# TIL: LLM CoT(Chain-of-Thought) & LAG(Latency-Aware Generation)

## LLM CoT (Chain-of-Thought)란?
**Chain-of-Thought(CoT)**는 대형 언어 모델(LLM)이 복잡한 문제를 해결할 때 **단계별 논리적 사고 과정**을 통해 답을 도출하도록 유도하는 기법이다.

### 🔹 핵심 원리
- **추론 능력 강화**: 단순한 응답 대신, 논리적 사고 과정을 포함.
- **단계적 사고 과정**: 복잡한 문제를 여러 단계로 나누어 설명.
- **Few-shot Prompting 활용**: 예제를 통해 모델이 논리적 사고를 학습하도록 유도.

### 🔹 예제
**문제**: "앨리스에게 사과 3개, 밥에게 사과 5개가 있다. 총합은?"
- **일반 응답**: "8"
- **CoT 적용 응답**:
  1. 앨리스에게 사과 3개가 있다.
  2. 밥에게 사과 5개가 있다.
  3. 총합은 3 + 5 = 8개이다.

➡ CoT 적용 시, 모델이 단계별 사고 과정을 포함한 응답을 생성함.

---

## LAG (Latency-Aware Generation)란?
**Latency-Aware Generation(LAG)**는 LLM이 **응답 속도(latency)를 고려하여 최적화**하는 방법이다. 사용자가 기다리는 시간을 줄이면서도 높은 품질의 응답을 유지하도록 설계됨.

### 🔹 핵심 원리
- **실시간 반응성 향상**: 빠른 응답 제공.
- **효율적인 리소스 사용**: 불필요한 연산 감소.
- **적응형 생성(adaptive generation)**: 텍스트 복잡도에 따라 응답 속도 조절.

### 🔹 기법 예시
- **토큰 단위 출력 속도 조절**: 긴 답변의 경우 개요를 먼저 제공 후, 상세 내용 추가.
- **캐싱(Cache) 활용**: 반복 질문 시 응답 속도 향상.
- **하드웨어 가속(GPU/TPU 활용)**: 연산 최적화.

---

## CoT vs. LAG 비교
| 개념  | Chain-of-Thought (CoT) | Latency-Aware Generation (LAG) |
|--------|------------------------|--------------------------------|
| **목적** | 논리적 사고 과정 개선 | 빠른 응답 생성 |
| **핵심 기능** | 단계별 추론을 유도 | 지연 시간 최소화 |
| **적용 분야** | 수학 문제, 논리적 추론 | 실시간 대화, 챗봇, 음성 비서 |
| **단점** | 응답 시간이 증가 가능 | 응답 품질 저하 가능 |

➡ CoT는 **논리적 사고 강화**, LAG는 **응답 속도 최적화**에 초점을 둠.
➡ 경우에 따라 **두 기법을 조합하여 최적의 성능을 달성**할 수도 있음.

