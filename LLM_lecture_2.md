# LLM 특강 (RAG)

## LLM 성능 향상 방법
### 프롬프팅
- 질문만 잘 조정해서 답을 얻어보는 방법
- 추가적은 데이터 훈련 없이 텍스트 입력 만으로 모델을 조정하는 방법
- 빠르고 비용이 들지 않지만 원래 학습한 데이터 기반으로 답변 가능
- 문맥으로 추가 데이터를 제공할 수 있으나 한계가 명확

### RAG
- 외부 데이터를 검색해서 모델이 최신 정보를 가지고 답변을 생성해내는 방법
- 즉 LLM과 검색 시스템을 결합해서 실시간으로 LLM이 필요한 정보를 검색하도록 도와주는 것
- 최신 정보 반영 가능하나 데이터에 의존성이 큼 Garbage in, Garbage Out

### Fine-Tuning
- 추가 훈련을 통해 도메인에 최적화 시키는 방법
- 비용이 큼

<u>정답은 없고 내 데이터와 내가 구현하고자 하는 서비스/도메인에 최적화된 방법을 사용해야함</u>


## RAG 이해하기
- 간단히 말하면

-- 검색증강생성 - 간단하게 검색을 좀 강화시켜서 생서해내는 기술

-- llm에서 나온 기술이 아닌, 태초의 NLP부터 사용된 기술

### Retrieval

-- 컴퓨터에 있는 특정 데이터를 가져오는 것

-- 즉, 외부 데이터를 모델이 가져오는 것

### Augmented(증강)
-- 정보를 증강해서 이미 현실에 있는 것처럼(알고 있는 것 처럼)

### Generation(생성)

## RAG를 쓴다?
-- 컴퓨터는 비슷한것을 찾기 위해 판단
--- 코사인 유사도
--- 유클리드 거리

-- 임베딩을 해야 가능

-- 같은 모델을 사용하고 같은 데이터를 임베딩 한다면 한 번 임베딩 한 벡터들을 '저장' 해놓고 사용합니다.

- retriever / Document Loader / Vector Store / Text Splitter / Embedding Model
>> 이 과정을 랭체인이 해줌

데이터를 로드
> 작은 단위로 Split
> 텍스트를 숫자로 바꾸는 Embed
>  벡터 DB에 저장
> 질문이 들어오면 그친구도 임베딩 하고
> 벡터DB에서 서치 후
질문이랑 DB내용을 잘 말아서
프롬프트에 넣고 LLM 가동