# LLM 특강 (RAG)

## LLM 성능 향상 방법

### 1. 프롬프팅 (Prompting)
- 질문을 효과적으로 조정하여 원하는 답변을 얻는 기법
- 추가적인 데이터 훈련 없이 텍스트 입력만으로 모델의 출력을 조정하는 방법
- 빠르고 비용이 들지 않지만, 모델이 학습한 데이터 범위 내에서만 답변 가능
- 문맥을 추가하여 정보를 보완할 수 있으나, 근본적인 지식 한계를 극복하기 어려움

### 2. RAG (Retrieval-Augmented Generation)
- 외부 데이터를 검색하여 LLM이 최신 정보를 바탕으로 답변을 생성하도록 하는 기법
- LLM과 검색 시스템을 결합하여 실시간으로 필요한 정보를 검색하고 활용
- 최신 정보 반영이 가능하지만, 검색된 데이터의 품질이 결과에 영향을 미침 (Garbage In, Garbage Out)

### 3. 파인 튜닝 (Fine-Tuning)
- 추가적인 훈련을 통해 특정 도메인에 최적화하는 방법
- 모델이 특정 데이터셋을 학습하여 도메인 특화된 응답을 제공할 수 있음
- 높은 비용과 많은 리소스가 필요함

> **최적의 방법은 존재하지 않으며, 사용자의 데이터와 서비스/도메인 특성에 맞춰 선택해야 함**

---

## RAG 이해하기

### 1. 개념
- **검색 증강 생성** (Retrieval-Augmented Generation): 검색을 강화하여 보다 정교한 답변을 생성하는 기술
- LLM에서 새롭게 등장한 개념이 아니라, 초기 NLP 기술에서도 사용되었던 방식

### 2. RAG의 구성 요소
1. **Retrieval (검색)**: 
   - 컴퓨터가 특정 데이터를 검색하여 가져오는 과정
   - 외부 데이터베이스나 문서에서 관련 정보를 찾아 제공

2. **Augmentation (증강)**:
   - 검색된 정보를 활용하여 모델이 마치 원래 알고 있던 것처럼 답변을 생성하는 과정

3. **Generation (생성)**:
   - 검색된 정보를 바탕으로 LLM이 최종적인 답변을 생성하는 단계

---

## RAG 구현 방식

### 1. 유사도 검색 기법
- 컴퓨터는 비슷한 정보를 찾기 위해 수학적 거리 개념을 활용
  - **코사인 유사도 (Cosine Similarity)**: 두 벡터 간의 각도를 비교하여 유사성을 평가
  - **유클리드 거리 (Euclidean Distance)**: 데이터 간의 거리를 측정하여 유사성 판단

### 2. 임베딩 (Embedding)
- 문서를 벡터 형식으로 변환하여 검색 가능하도록 처리하는 과정
- 동일한 모델과 데이터를 사용하여 한 번 임베딩한 벡터를 저장 후 재사용 가능

### 3. RAG의 핵심 구성 요소
- **Retriever (검색기)**: 적절한 문서를 검색하는 역할
- **Document Loader (문서 로더)**: 문서를 불러와서 처리하는 모듈
- **Vector Store (벡터 저장소)**: 문서를 임베딩하여 저장하는 데이터베이스
- **Text Splitter (텍스트 분할기)**: 문서를 작은 단위로 나누어 검색 효율을 높임
- **Embedding Model (임베딩 모델)**: 텍스트를 벡터로 변환하는 모델

### 4. RAG 처리 과정
1. **데이터 로드**: 문서를 불러옴
2. **텍스트 분할**: 문서를 작은 단위로 나눔
3. **임베딩 생성**: 텍스트를 숫자로 변환
4. **벡터 DB 저장**: 변환된 데이터를 벡터 데이터베이스에 저장
5. **질문 임베딩**: 사용자의 질문도 벡터로 변환
6. **벡터 검색**: 데이터베이스에서 유사한 정보를 검색
7. **프롬프트 구성**: 검색된 정보와 질문을 조합하여 프롬프트 생성
8. **LLM 실행**: 최종적인 답변 생성

이 과정을 자동화하는 대표적인 프레임워크로 **LangChain**이 있음.